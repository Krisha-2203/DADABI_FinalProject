{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f0149f0-616d-48bd-a986-806692bfdfa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Configuration\n",
    "VOLUME_PATH = \"/Volumes/workspace/imdb_final_project/imdb\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Bronze Layer - Raw Data Ingestion\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: name_basics\n",
    "@dlt.table(\n",
    "    name=\"bronze_name_basics\",\n",
    "    comment=\"Bronze layer - Raw name basics data from CSV\",\n",
    "    table_properties={\n",
    "        \"quality\": \"bronze\",\n",
    "        \"pipelines.autoOptimize.managed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def bronze_name_basics():\n",
    "    schema = StructType([\n",
    "        StructField(\"nconst\", StringType(), True),\n",
    "        StructField(\"primaryName\", StringType(), True),\n",
    "        StructField(\"birthYear\", StringType(), True),\n",
    "        StructField(\"deathYear\", StringType(), True),\n",
    "        StructField(\"primaryProfession\", StringType(), True),\n",
    "        StructField(\"knownForTitles\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_name_basics.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_basics\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_basics\",\n",
    "    comment=\"Bronze layer - Raw title basics data from CSV\"\n",
    ")\n",
    "def bronze_title_basics():\n",
    "    schema = StructType([\n",
    "        StructField(\"tconst\", StringType(), True),\n",
    "        StructField(\"titleType\", StringType(), True),\n",
    "        StructField(\"primaryTitle\", StringType(), True),\n",
    "        StructField(\"originalTitle\", StringType(), True),\n",
    "        StructField(\"isAdult\", StringType(), True),\n",
    "        StructField(\"startYear\", StringType(), True),\n",
    "        StructField(\"endYear\", StringType(), True),\n",
    "        StructField(\"runtimeMinutes\", StringType(), True),\n",
    "        StructField(\"genres\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_basics.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_akas\n",
    "@dlt.table(  # ← Missing @ symbol\n",
    "    name=\"bronze_title_akas\",\n",
    "    comment=\"Bronze layer - Raw title akas data from CSV\"\n",
    ")\n",
    "def bronze_title_akas():\n",
    "    schema = StructType([\n",
    "        StructField(\"titleId\", StringType(), True),\n",
    "        StructField(\"ordering\", StringType(), True),\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"region\", StringType(), True),\n",
    "        StructField(\"language\", StringType(), True),\n",
    "        StructField(\"types\", StringType(), True),\n",
    "        StructField(\"attributes\", StringType(), True),\n",
    "        StructField(\"isOriginalTitle\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"encoding\", \"UTF-8\")\n",
    "        .option(\"charset\", \"UTF-8\")\n",
    "        .option(\"multiLine\", \"true\")\n",
    "        .option(\"mode\", \"PERMISSIVE\")\n",
    "        .option(\"escape\", \"\\\"\")  # ← Removed duplicate, kept double-quote\n",
    "        .option(\"quote\", \"\\\"\")   # ← Removed duplicate\n",
    "        .option(\"ignoreLeadingWhiteSpace\", \"false\")\n",
    "        .option(\"ignoreTrailingWhiteSpace\", \"false\")\n",
    "        .option(\"emptyValue\", \"unknown\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_akas.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_crew\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_crew\",\n",
    "    comment=\"Bronze layer - Raw title crew data from CSV\"\n",
    ")\n",
    "def bronze_title_crew():\n",
    "    schema = StructType([\n",
    "        StructField(\"tconst\", StringType(), True),\n",
    "        StructField(\"directors\", StringType(), True),\n",
    "        StructField(\"writers\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_crew.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_episode\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_episode\",\n",
    "    comment=\"Bronze layer - Raw title episode data from CSV\"\n",
    ")\n",
    "def bronze_title_episode():\n",
    "    schema = StructType([\n",
    "        StructField(\"tconst\", StringType(), True),\n",
    "        StructField(\"parentTconst\", StringType(), True),\n",
    "        StructField(\"seasonNumber\", StringType(), True),\n",
    "        StructField(\"episodeNumber\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_episode.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_principals\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_principals\",\n",
    "    comment=\"Bronze layer - Raw title principals data from CSV\"\n",
    ")\n",
    "def bronze_title_principals():\n",
    "    schema = StructType([\n",
    "        StructField(\"tconst\", StringType(), True),\n",
    "        StructField(\"ordering\", StringType(), True),\n",
    "        StructField(\"nconst\", StringType(), True),\n",
    "        StructField(\"category\", StringType(), True),\n",
    "        StructField(\"job\", StringType(), True),\n",
    "        StructField(\"characters\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_principals.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Bronze: title_ratings\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_ratings\",\n",
    "    comment=\"Bronze layer - Raw title ratings data from CSV\"\n",
    ")\n",
    "def bronze_title_ratings():\n",
    "    schema = StructType([\n",
    "        StructField(\"tconst\", StringType(), True),\n",
    "        StructField(\"averageRating\", StringType(), True),\n",
    "        StructField(\"numVotes\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(f\"{VOLUME_PATH}/Cleaned_title_ratings.csv\")\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994f0fc8-7397-4f45-8ad9-b377601ee593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# ============================================================\n",
    "#                   SILVER LAYER\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: name_basics\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_name_basics\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_nconst\", \"nconst IS NOT NULL\")\n",
    "def silver_name_basics():\n",
    "    return (\n",
    "        dlt.read(\"bronze_name_basics\")\n",
    "        .withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "        .withColumn(\"deathYear\", col(\"deathYear\").cast(\"int\"))\n",
    "        .withColumn(\"primaryName\", col(\"primaryName\").cast(\"string\"))\n",
    "        .withColumn(\"primaryProfession\", col(\"primaryProfession\").cast(\"string\"))\n",
    "        .withColumn(\"knownForTitles\", col(\"knownForTitles\").cast(\"string\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_basics\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_basics\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "def silver_title_basics():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_basics\")\n",
    "        .withColumn(\"titleType\", col(\"titleType\").cast(\"string\"))\n",
    "        .withColumn(\"primaryTitle\", col(\"primaryTitle\").cast(\"string\"))\n",
    "        .withColumn(\"originalTitle\", col(\"originalTitle\").cast(\"string\"))\n",
    "        .withColumn(\"isAdult\", col(\"isAdult\").cast(\"int\"))\n",
    "        .withColumn(\"startYear\", col(\"startYear\").cast(\"int\"))\n",
    "        .withColumn(\"endYear\", col(\"endYear\").cast(\"int\"))\n",
    "        .withColumn(\"runtimeMinutes\", col(\"runtimeMinutes\").cast(\"int\"))\n",
    "        .withColumn(\"genres\", col(\"genres\").cast(\"string\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_akas\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_akas\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_titleId\", \"titleId IS NOT NULL\")\n",
    "def silver_title_akas():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_akas\")\n",
    "        .withColumn(\"ordering\", col(\"ordering\").cast(\"int\"))\n",
    "        .withColumn(\"title\", col(\"title\").cast(\"string\"))\n",
    "        .withColumn(\"region\", col(\"region\").cast(\"string\"))\n",
    "        .withColumn(\"language\", col(\"language\").cast(\"string\"))\n",
    "        .withColumn(\"types\", col(\"types\").cast(\"string\"))\n",
    "        .withColumn(\"attributes\", col(\"attributes\").cast(\"string\"))\n",
    "        .withColumn(\"isOriginalTitle\", col(\"isOriginalTitle\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_episode\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "def silver_title_episode():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_episode\")\n",
    "        .withColumn(\"parentTconst\", col(\"parentTconst\").cast(\"string\"))\n",
    "        .withColumn(\"seasonNumber\", col(\"seasonNumber\").cast(\"int\"))\n",
    "        .withColumn(\"episodeNumber\", col(\"episodeNumber\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_principals\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_principals\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_nconst\", \"nconst IS NOT NULL\")\n",
    "def silver_title_principals():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_principals\")\n",
    "        .withColumn(\"ordering\", col(\"ordering\").cast(\"long\"))\n",
    "        .withColumn(\"category\", col(\"category\").cast(\"string\"))\n",
    "        .withColumn(\"job\", col(\"job\").cast(\"string\"))\n",
    "        .withColumn(\"characters\", col(\"characters\").cast(\"string\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_ratings\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_ratings\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "def silver_title_ratings():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_ratings\")\n",
    "        .withColumn(\"averageRating\", col(\"averageRating\").cast(\"float\"))\n",
    "        .withColumn(\"numVotes\", col(\"numVotes\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Silver: title_crew\n",
    "# ------------------------------------------------------------\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew\",\n",
    "    comment=\"Silver layer - Datatype mapping only\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "def silver_title_crew():\n",
    "    return (\n",
    "        dlt.read(\"bronze_title_crew\")\n",
    "        .withColumn(\"directors\", col(\"directors\").cast(\"string\"))\n",
    "        .withColumn(\"writers\", col(\"writers\").cast(\"string\"))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "122cea09-8df3-450c-a98a-fab03850251c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Gold Layer - Complete Dimensional Model\n",
    "# MAGIC \n",
    "# MAGIC **Architecture:** Medallion Architecture - Gold Layer\n",
    "# MAGIC **Purpose:** Business-ready dimensional model (Star Schema)\n",
    "# MAGIC **Reference Data:** Uses static CSV files for Region and Language dimensions\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Configuration\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Volume path configuration\n",
    "VOLUME_PATH = \"/Volumes/workspace/imdb_final_project/imdb\"\n",
    "REGION_REFERENCE_FILE = f\"{VOLUME_PATH}/region_reference.csv\"\n",
    "LANGUAGE_REFERENCE_FILE = f\"{VOLUME_PATH}/language_reference.csv\"\n",
    "\n",
    "print(f\"Volume Path: {VOLUME_PATH}\")\n",
    "print(f\"Region Reference: {REGION_REFERENCE_FILE}\")\n",
    "print(f\"Language Reference: {LANGUAGE_REFERENCE_FILE}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Helper Functions for Reference Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def load_region_reference():\n",
    "    \"\"\"\n",
    "    Load region reference data from CSV file\n",
    "    File: /Volumes/workspace/imdb_final_project/imdb/region_reference.csv\n",
    "    Expected columns: RegionCode, RegionDescription\n",
    "    \"\"\"\n",
    "    region_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(REGION_REFERENCE_FILE)\n",
    "    )\n",
    "    \n",
    "    row_count = region_df.count()\n",
    "    print(f\"Loaded {row_count} regions from reference file\")\n",
    "    \n",
    "    return region_df\n",
    "\n",
    "def load_language_reference():\n",
    "    \"\"\"\n",
    "    Load language reference data from CSV file\n",
    "    File: /Volumes/workspace/imdb_final_project/imdb/language_reference.csv\n",
    "    Expected columns: LanguageCode, LanguageDescription\n",
    "    \"\"\"\n",
    "    language_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(LANGUAGE_REFERENCE_FILE)\n",
    "    )\n",
    "    \n",
    "    row_count = language_df.count()\n",
    "    print(f\"Loaded {row_count} languages from reference file\")\n",
    "    \n",
    "    return language_df\n",
    "\n",
    "print(\"Helper functions loaded successfully\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## DIMENSION TABLES\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 1. DIM_Region\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Region\",\n",
    "    comment=\"Complete Region dimension based only on reference list\"\n",
    ")\n",
    "def gold_DIM_Region():\n",
    "\n",
    "    reference_regions = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(\"/Volumes/workspace/imdb_final_project/imdb/region_reference.csv\")\n",
    "        .select(\n",
    "            lower(col(\"RegionCode\")).alias(\"RegionCode\"),\n",
    "            col(\"RegionDescription\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_df = (\n",
    "        reference_regions\n",
    "        .withColumn(\"RegionKey\", row_number().over(Window.orderBy(\"RegionCode\")))\n",
    "        .select(\"RegionKey\", \"RegionCode\", \"RegionDescription\")\n",
    "    )\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 2. DIM_Language\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Language\",\n",
    "    comment=\"Complete Language dimension based only on reference list\"\n",
    ")\n",
    "def gold_DIM_Language():\n",
    "\n",
    "    reference_languages = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(\"/Volumes/workspace/imdb_final_project/imdb/language_reference.csv\")\n",
    "        .select(\n",
    "            lower(col(\"LanguageCode\")).alias(\"LanguageCode\"),\n",
    "            col(\"LanguageDescription\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_df = (\n",
    "        reference_languages\n",
    "        .withColumn(\"LanguageKey\", row_number().over(Window.orderBy(\"LanguageCode\")))\n",
    "        .select(\"LanguageKey\", \"LanguageCode\", \"LanguageDescription\")\n",
    "    )\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 3. DIM_NAME (Person Dimension)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_NAME\",\n",
    "    comment=\"Person dimension - SCD Type 1 (complete refresh each run)\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_nconst\", \"nconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_name\", \"primaryName IS NOT NULL\")\n",
    "def gold_DIM_NAME():\n",
    "    \"\"\"\n",
    "    SCD Type 1: Simple complete refresh\n",
    "    Old data is replaced with new data each run\n",
    "    ModifiedDate tracks when the record was last updated\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dlt.read(\"silver_name_basics\")\n",
    "        .select(\n",
    "            col(\"nconst\").alias(\"NCONST\"),\n",
    "            col(\"primaryName\").alias(\"PrimaryName\"),\n",
    "            col(\"birthYear\").alias(\"BirthYear\"),\n",
    "            col(\"deathYear\").alias(\"DeathYear\")\n",
    "        )\n",
    "        .withColumn(\"ModifiedDate\", current_timestamp())\n",
    "        .withColumn(\"NameKey\", row_number().over(Window.orderBy(\"nconst\")))\n",
    "        .select(\n",
    "            \"NameKey\",\n",
    "            \"NCONST\",\n",
    "            \"PrimaryName\",\n",
    "            \"BirthYear\",\n",
    "            \"DeathYear\",\n",
    "            \"ModifiedDate\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 4. DIM_Title (Title Dimension)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Title\",\n",
    "    comment=\"Title dimension - SCD Type 2 (tracks history with effective dates)\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst\", \"tconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_title\", \"primaryTitle IS NOT NULL\")\n",
    "def gold_DIM_Title():\n",
    "    \"\"\"\n",
    "    SCD Type 2: Simplified version\n",
    "    - EffectiveDate: When record became active\n",
    "    - EndDate: When record expired (9999-12-31 for current)\n",
    "    - IsCurrent: Boolean flag for current version\n",
    "    - CreatedDate: When record was first created\n",
    "    - ModifiedDate: When record was last modified\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dlt.read(\"silver_title_basics\")\n",
    "        .select(\n",
    "            col(\"tconst\").alias(\"Tconst\"),\n",
    "            col(\"titleType\").alias(\"TitleType\"),\n",
    "            col(\"primaryTitle\").alias(\"PrimaryTitle\"),\n",
    "            col(\"originalTitle\").alias(\"OriginalTitle\"),\n",
    "            col(\"isAdult\").alias(\"IsAdult\"),\n",
    "            col(\"startYear\").alias(\"ReleaseYear\"),\n",
    "            col(\"runtimeMinutes\").alias(\"RuntimeMinutes\")\n",
    "        )\n",
    "        .withColumn(\"EffectiveDate\", current_timestamp())\n",
    "        .withColumn(\"EndDate\", lit(\"9999-12-31 23:59:59\").cast(\"timestamp\"))\n",
    "        .withColumn(\"IsCurrent\", lit(True))\n",
    "        .withColumn(\"CreatedDate\", current_timestamp())\n",
    "        .withColumn(\"ModifiedDate\", current_timestamp())\n",
    "        .withColumn(\"TitleKey\", row_number().over(Window.orderBy(\"tconst\")))\n",
    "        .select(\n",
    "            \"TitleKey\",\n",
    "            \"Tconst\",\n",
    "            \"TitleType\",\n",
    "            \"PrimaryTitle\",\n",
    "            \"OriginalTitle\",\n",
    "            \"IsAdult\",\n",
    "            \"ReleaseYear\",\n",
    "            \"RuntimeMinutes\",\n",
    "            \"EffectiveDate\",\n",
    "            \"EndDate\",\n",
    "            \"IsCurrent\",\n",
    "            \"CreatedDate\",\n",
    "            \"ModifiedDate\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 5. DIM_Genre\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Genre\",\n",
    "    comment=\"Genre dimension extracted from comma-separated genres\"\n",
    ")\n",
    "def gold_DIM_Genre():\n",
    "    # Define valid genres in lowercase to match source data\n",
    "    valid_genres = [\n",
    "        'action', 'adult', 'adventure', 'animation', 'biography',\n",
    "        'comedy', 'crime', 'documentary', 'drama', 'family',\n",
    "        'fantasy', 'film-noir', 'game-show', 'history', 'horror',\n",
    "        'music', 'musical', 'mystery', 'news', 'reality-tv',\n",
    "        'romance', 'sci-fi', 'short', 'sport', 'talk-show',\n",
    "        'thriller', 'war', 'western'\n",
    "    ]\n",
    "    \n",
    "    return (\n",
    "        dlt.read(\"silver_title_basics\")\n",
    "        .select(explode(split(col(\"genres\"), \",\")).alias(\"GenreName\"))\n",
    "        .filter(col(\"GenreName\").isNotNull())\n",
    "        .withColumn(\"GenreName\", trim(col(\"GenreName\")))\n",
    "        # Filter out empty strings\n",
    "        .filter(col(\"GenreName\") != \"\")\n",
    "        # Filter out \"\\\\N\" (IMDB's null representation)\n",
    "        .filter(col(\"GenreName\") != \"\\\\N\")\n",
    "        # Convert to lowercase for comparison\n",
    "        .withColumn(\"GenreName_lower\", lower(col(\"GenreName\")))\n",
    "        # Only keep valid genres\n",
    "        .filter(col(\"GenreName_lower\").isin(valid_genres))\n",
    "        # Convert to Title Case for display\n",
    "        .withColumn(\"GenreName\", initcap(col(\"GenreName_lower\")))\n",
    "        .drop(\"GenreName_lower\")\n",
    "        .distinct()\n",
    "        .withColumn(\"GenreKey\", row_number().over(Window.orderBy(\"GenreName\")))\n",
    "        .select(\"GenreKey\", \"GenreName\")\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 6. DIM_Profession\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Profession\",\n",
    "    comment=\"Profession dimension extracted from comma-separated professions\"\n",
    ")\n",
    "def gold_DIM_Profession():\n",
    "    return (\n",
    "        dlt.read(\"silver_name_basics\")\n",
    "        .select(explode(split(col(\"primaryProfession\"), \",\")).alias(\"Profession\"))\n",
    "        .filter(col(\"Profession\").isNotNull())\n",
    "        .withColumn(\"Profession\", trim(col(\"Profession\")))\n",
    "        .distinct()\n",
    "        .withColumn(\"ProfessionKey\", row_number().over(Window.orderBy(\"Profession\")))\n",
    "        .select(\"ProfessionKey\", \"Profession\")\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 7. DIM_Crew\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Crew\",\n",
    "    comment=\"Crew role dimension\"\n",
    ")\n",
    "def gold_DIM_Crew():\n",
    "    crew_roles = [\n",
    "        {'CrewKey': 1, 'Crew_Role': 'director'},\n",
    "        {'CrewKey': 2, 'Crew_Role': 'writer'}\n",
    "    ]\n",
    "    return spark.createDataFrame(crew_roles)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 8. DIM_Principals (Type 6 Dimension)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_DIM_Principals\",\n",
    "    comment=\"Principal cast and crew dimension - SCD Type 1\"\n",
    ")\n",
    "def gold_DIM_Principals():\n",
    "    \"\"\"\n",
    "    SCD Type 1: Simple implementation that rebuilds the table on each run\n",
    "    ModifiedDate tracks when the record was last updated\n",
    "    \"\"\"\n",
    "    # Read sources\n",
    "    principals = dlt.read(\"silver_title_principals\")\n",
    "    titles = dlt.read(\"gold_DIM_Title\").filter(col(\"IsCurrent\") == True)  # Only current titles\n",
    "    names = dlt.read(\"gold_DIM_NAME\")\n",
    "    \n",
    "    # Simple join and transform\n",
    "    result = (\n",
    "        principals\n",
    "        .join(names, principals.nconst == names.NCONST, \"inner\")\n",
    "        .join(titles, principals.tconst == titles.Tconst, \"inner\")\n",
    "        .select(\n",
    "            names.NameKey.alias(\"NameKey\"),\n",
    "            titles.TitleKey.alias(\"TitleKey\"),\n",
    "            principals.ordering.alias(\"Ordering\"),\n",
    "            principals.category.alias(\"Category\"),\n",
    "            principals.job.alias(\"Job\"),\n",
    "            principals.characters.alias(\"Characters\")\n",
    "        )\n",
    "        .filter(col(\"NameKey\").isNotNull())\n",
    "        .withColumn(\"ModifiedDate\", current_timestamp())\n",
    "        .withColumn(\"PrincipalKey\", row_number().over(Window.orderBy(\"TitleKey\", \"Ordering\")))\n",
    "        .select(\n",
    "            \"PrincipalKey\",\n",
    "            \"NameKey\",\n",
    "            \"TitleKey\",\n",
    "            \"Ordering\",\n",
    "            \"Category\",\n",
    "            \"Job\",\n",
    "            \"Characters\",\n",
    "            \"ModifiedDate\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## FACT TABLES\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 9. FACT_Title_Ratings\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_FACT_Title_Ratings\",\n",
    "    comment=\"Fact table for title ratings\"\n",
    ")\n",
    "def gold_FACT_Title_Ratings():\n",
    "    # Read sources\n",
    "    ratings = dlt.read(\"silver_title_ratings\")\n",
    "    titles = dlt.read(\"gold_DIM_Title\")\n",
    "    \n",
    "    # Perform join and select with explicit column references\n",
    "    result = (\n",
    "        ratings\n",
    "        .join(titles, ratings.tconst == titles.Tconst, \"inner\")\n",
    "        .select(\n",
    "            ratings.tconst.alias(\"tconst\"),  # Explicitly use ratings.tconst\n",
    "            titles.TitleKey.alias(\"TitleKey\"),\n",
    "            ratings.averageRating.alias(\"AverageRating\"),\n",
    "            ratings.numVotes.alias(\"NumVotes\")\n",
    "        )\n",
    "        .filter(col(\"tconst\").isNotNull())  # Now unambiguous\n",
    "        .filter((col(\"AverageRating\") >= 0) & (col(\"AverageRating\") <= 10))  # Quality check\n",
    "        .withColumn(\"RatingKey\", row_number().over(Window.orderBy(\"tconst\")))\n",
    "        .select(\n",
    "            \"RatingKey\",\n",
    "            \"TitleKey\",\n",
    "            \"AverageRating\",\n",
    "            \"NumVotes\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 10. FACT_Episodes\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_FACT_Episodes\",\n",
    "    comment=\"Fact table for TV episodes\"\n",
    ")\n",
    "def gold_FACT_Episodes():\n",
    "    # Read sources with aliases\n",
    "    episodes = dlt.read(\"silver_title_episode\")\n",
    "    titles = dlt.read(\"gold_DIM_Title\")\n",
    "    \n",
    "    # Perform join and select with explicit column references\n",
    "    result = (\n",
    "        episodes\n",
    "        .join(titles, episodes.tconst == titles.Tconst, \"inner\")\n",
    "        .select(\n",
    "            episodes.tconst.alias(\"tconst\"),  # Explicitly use episodes.tconst\n",
    "            titles.TitleKey.alias(\"TitleKey\"),\n",
    "            episodes.seasonNumber.alias(\"SeasonNumber\"),\n",
    "            episodes.episodeNumber.alias(\"EpisodeNumber\")\n",
    "        )\n",
    "        .filter(col(\"tconst\").isNotNull())  # Now unambiguous\n",
    "        .withColumn(\"EpisodeKey\", row_number().over(Window.orderBy(\"tconst\")))\n",
    "        .select(\n",
    "            \"EpisodeKey\",\n",
    "            \"TitleKey\",\n",
    "            \"SeasonNumber\",\n",
    "            \"EpisodeNumber\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## BRIDGE TABLES\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 11. BRIDGE_TITLE_GENRE\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_BRIDGE_TITLE_GENRE\",\n",
    "    comment=\"Bridge table linking titles to genres (many-to-many, up to 3 genres per title)\"\n",
    ")\n",
    "def gold_BRIDGE_TITLE_GENRE():\n",
    "    titles = dlt.read(\"gold_DIM_Title\")\n",
    "    genres = dlt.read(\"gold_DIM_Genre\")\n",
    "    \n",
    "    # Explode genres from comma-separated values (up to 3 genres)\n",
    "    titles_with_genres = (\n",
    "        dlt.read(\"silver_title_basics\")\n",
    "        .select(\n",
    "            \"tconst\",\n",
    "            posexplode(split(col(\"genres\"), \",\")).alias(\"genre_position\", \"GenreName\")\n",
    "        )\n",
    "        .withColumn(\"GenreName\", trim(col(\"GenreName\")))\n",
    "        .filter(col(\"GenreName\").isNotNull())\n",
    "        .filter(col(\"GenreName\") != \"\")\n",
    "        .filter(col(\"GenreName\") != \"\\\\N\")  # Filter out IMDB null values\n",
    "        # Convert to Title Case to match gold_DIM_Genre format\n",
    "        .withColumn(\"GenreName\", initcap(col(\"GenreName\")))\n",
    "        .filter(col(\"genre_position\") < 3)  # Ensure max 3 genres (positions 0, 1, 2)\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        titles_with_genres\n",
    "        .join(titles, titles_with_genres.tconst == titles.Tconst, \"inner\")\n",
    "        # Inner join will automatically filter out invalid genres not in DIM_Genre\n",
    "        .join(genres, titles_with_genres.GenreName == genres.GenreName, \"inner\")\n",
    "        .select(\n",
    "            row_number().over(Window.orderBy(\"TitleKey\", \"GenreKey\")).alias(\"TitleGenreKey\"),\n",
    "            col(\"TitleKey\"),\n",
    "            col(\"GenreKey\"),\n",
    "            col(\"genre_position\").alias(\"GenreOrder\")  # Track order (0=primary, 1=secondary, 2=tertiary)\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 12. BRIDGE_PROFESSION\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_BRIDGE_PROFESSION\",\n",
    "    comment=\"Bridge table linking people to professions (many-to-many) with IsPrimary flag\"\n",
    ")\n",
    "def gold_BRIDGE_PROFESSION():\n",
    "    # Explode professions from comma-separated values\n",
    "    # posexplode gives us position (0 = primary profession)\n",
    "    names_with_professions = (\n",
    "        dlt.read(\"silver_name_basics\")\n",
    "        .select(\n",
    "            \"nconst\",\n",
    "            posexplode(split(col(\"primaryProfession\"), \",\")).alias(\"position\", \"Profession\")\n",
    "        )\n",
    "        .withColumn(\"Profession\", trim(col(\"Profession\")))\n",
    "        .withColumn(\"IsPrimary\", when(col(\"position\") == 0, 1).otherwise(0))\n",
    "        .filter(col(\"Profession\").isNotNull())\n",
    "    )\n",
    "    \n",
    "    names = dlt.read(\"gold_DIM_NAME\")\n",
    "    professions = dlt.read(\"gold_DIM_Profession\")\n",
    "    \n",
    "    return (\n",
    "        names_with_professions\n",
    "        .join(names, names_with_professions.nconst == names.NCONST, \"inner\")\n",
    "        .join(professions, names_with_professions.Profession == professions.Profession, \"inner\")\n",
    "        .select(\n",
    "            row_number().over(Window.orderBy(\"NameKey\", \"ProfessionKey\")).alias(\"titleProfessionKey\"),\n",
    "            col(\"ProfessionKey\"),\n",
    "            col(\"NameKey\"),\n",
    "            col(\"IsPrimary\")\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 13. Bridge_Title_Crew\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_Bridge_Title_Crew\",\n",
    "    comment=\"Bridge table linking titles to crew members (directors and writers)\"\n",
    ")\n",
    "def gold_Bridge_Title_Crew():\n",
    "    crew = dlt.read(\"silver_title_crew\")\n",
    "    titles = dlt.read(\"gold_DIM_Title\")\n",
    "    names = dlt.read(\"gold_DIM_NAME\")\n",
    "    dim_crew = dlt.read(\"gold_DIM_Crew\")\n",
    "    \n",
    "    # Explode directors\n",
    "    directors = (\n",
    "        crew\n",
    "        .select(\"tconst\", explode(split(col(\"directors\"), \",\")).alias(\"nconst\"))\n",
    "        .withColumn(\"nconst\", trim(col(\"nconst\")))\n",
    "        .withColumn(\"role\", lit(\"director\"))\n",
    "        .filter(col(\"nconst\").isNotNull())\n",
    "        .filter(col(\"nconst\") != \"\")\n",
    "    )\n",
    "    \n",
    "    # Explode writers\n",
    "    writers = (\n",
    "        crew\n",
    "        .select(\"tconst\", explode(split(col(\"writers\"), \",\")).alias(\"nconst\"))\n",
    "        .withColumn(\"nconst\", trim(col(\"nconst\")))\n",
    "        .withColumn(\"role\", lit(\"writer\"))\n",
    "        .filter(col(\"nconst\").isNotNull())\n",
    "        .filter(col(\"nconst\") != \"\")\n",
    "    )\n",
    "    \n",
    "    # Union directors and writers\n",
    "    all_crew = directors.union(writers)\n",
    "    \n",
    "    return (\n",
    "        all_crew\n",
    "        .join(titles, all_crew.tconst == titles.Tconst, \"inner\")\n",
    "        .join(names, all_crew.nconst == names.NCONST, \"inner\")\n",
    "        .join(dim_crew, all_crew.role == lower(dim_crew.Crew_Role), \"inner\")\n",
    "        .select(\n",
    "            row_number().over(Window.orderBy(\"TitleKey\", \"NameKey\", \"CrewKey\")).alias(\"titleCrewKey\"),\n",
    "            col(\"CrewKey\"),\n",
    "            col(\"TitleKey\"),\n",
    "            col(\"NameKey\")\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### 14. BRIDGE_Akas\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_BRIDGE_Akas\",\n",
    "    comment=\"Bridge table for title alternate names (akas) with regional variations\"\n",
    ")\n",
    "def gold_BRIDGE_Akas():\n",
    "    akas = dlt.read(\"silver_title_akas\")\n",
    "    titles = dlt.read(\"gold_DIM_Title\")\n",
    "    regions = dlt.read(\"gold_DIM_Region\")\n",
    "    languages = dlt.read(\"gold_DIM_Language\")\n",
    "    \n",
    "    return (\n",
    "        akas\n",
    "        # Filter out rows with encoding issues\n",
    "        .filter(~col(\"title\").rlike(\"[?�]\"))\n",
    "        .filter(col(\"title\").isNotNull())\n",
    "        .filter(col(\"titleId\").isNotNull())\n",
    "        \n",
    "        # Joins\n",
    "        .join(titles, akas.titleId == titles.Tconst, \"inner\")\n",
    "        .join(regions, akas.region == regions.RegionCode, \"left\")\n",
    "        .join(languages, akas.language == languages.LanguageCode, \"left\")\n",
    "        \n",
    "        # Replace NULLs with -9999\n",
    "        .withColumn(\"RegionKey\", coalesce(col(\"RegionKey\"), lit(-9999)))\n",
    "        .withColumn(\"LanguageKey\", coalesce(col(\"LanguageKey\"), lit(-9999)))\n",
    "\n",
    "        # Final output\n",
    "        .select(\n",
    "            row_number().over(Window.orderBy(\"TitleKey\", \"ordering\")).alias(\"TitleAkasKey\"),\n",
    "            col(\"TitleKey\"),\n",
    "            col(\"RegionKey\"),\n",
    "            col(\"LanguageKey\"),\n",
    "            col(\"title\").alias(\"AkasTitle\"),\n",
    "            col(\"isOriginalTitle\").alias(\"IsOriginalTitle\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Data Quality Summary\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\"\"\n",
    "Gold Layer Implementation Complete!\n",
    "\n",
    "DIMENSIONS (8):\n",
    "1. gold_DIM_Region - Region codes with descriptions (static file)\n",
    "2. gold_DIM_Language - Language codes with descriptions (static file)\n",
    "3. gold_DIM_NAME - Person information\n",
    "4. gold_DIM_Title - Movie/TV show information\n",
    "5. gold_DIM_Genre - Genre dimension\n",
    "6. gold_DIM_Profession - Profession dimension\n",
    "7. gold_DIM_Crew - Crew role dimension\n",
    "8. gold_DIM_Principals - Principal cast/crew (Type 6 SCD)\n",
    "\n",
    "FACTS (2):\n",
    "9. gold_FACT_Title_Ratings - Title ratings and votes\n",
    "10. gold_FACT_Episodes - TV episode information\n",
    "\n",
    "BRIDGES (4):\n",
    "11. gold_BRIDGE_TITLE_GENRE - Title to Genre many-to-many\n",
    "12. gold_BRIDGE_PROFESSION - Person to Profession many-to-many (with IsPrimary)\n",
    "13. gold_Bridge_Title_Crew - Title to Crew many-to-many\n",
    "14. gold_BRIDGE_Akas - Title to Regional names with language support\n",
    "\n",
    "REFERENCE DATA:\n",
    "- Region descriptions loaded from: /Volumes/workspace/imdb_final_project/imdb/region_reference.csv\n",
    "- Language descriptions loaded from: /Volumes/workspace/imdb_final_project/imdb/language_reference.csv\n",
    "\n",
    "DATA QUALITY:\n",
    "- Null handling with DLT expectations\n",
    "- Encoding issues filtered in BRIDGE_Akas\n",
    "- Primary professions marked with IsPrimary flag\n",
    "- Surrogate keys generated using row_number()\n",
    "- Inner joins ensure referential integrity\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IMDB_FinalProject_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
